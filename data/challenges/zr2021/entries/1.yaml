author_label: <b>Phone topline</b>
index: 2
lexical_all:
- 0.979
- 0.9767
lexical_invocab:
- '-'
- '-'
more:
  description:
    affiliation: EHESS, ENS, PSL Research Univerity, CNRS and Inria
    author: Zero Speech Challenge Organizers
    description: The BERT model trained on the phonetic transcriptions of the LibriSpeech
      960h dataset.
    gpu_budget: 1536
    open_source: false
    submitted_at: '2020-11-23T11:51:09+00:00'
    train_set: LibriSpeech 960h dataset
phonetic_clean_across:
- '-'
- '-'
phonetic_clean_within:
- '-'
- '-'
phonetic_other_across:
- '-'
- '-'
phonetic_other_within:
- '-'
- '-'
semantic_librispeech:
- 16.11
- 20.16
semantic_synthetic:
- 9.86
- 12.23
set:
- dev
- test
syntactic:
- 0.6678
- 0.6691
weighted_semantic_librispeech:
- 16.11
- 11.28
weighted_semantic_synthetic:
- 9.86
- 14.32
