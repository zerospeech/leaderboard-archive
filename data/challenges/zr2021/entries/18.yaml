author_label: Kim et al.
index: 19
lexical_all:
- 0.5168125
- 0.513603125
lexical_invocab:
- 0.5287017199999999
- 0.51912917
more:
  description:
    affiliation: Seoul National University
    author: Kyogu Lee, Jaeyeon Kim, Injune Hwang
    description: WPBERT, a BERT-small based language model trained using both word
      and phonetic representations. Used pretrained ResDAVEnet-VQ vq3 embeddings as
      word representations, vq2 embeddings as phonetic representations. Instead of
      directly using the embeddigns, for this version of the submission, we first
      changed them to integer values based on the codebook, then trained the language
      model. Also, we took the representations from the layer that gave less biased
      result for librispeech and synthetic datatset compared to the earlier submission.
    gpu_budget: 7.0
    open_source: false
    parameters:
      phonetic:
        frame_shift: 0.02
        metric: cosine
      semantic:
        metric: cosine
        pooling: mean
    submitted_at: '2021-11-03T23:55:34+00:00'
    train_set: ResDAVEnet-VQ was pretrained on PlacesAudio. WPBERT was trained on
      LibriSpeech960. Not along with VAD.
    visually_grounded: true
  lexical:
    by_frequency:
    - frequency: oov
      n_dev: 5000
      n_test: 20000
      score_dev: 0.5049
      score_test: 0.5081
      std_dev: 0.291
      std_test: 0.2909
    - frequency: 1-5
      n_dev: 1656
      n_test: 6788
      score_dev: 0.5192
      score_test: 0.5164
      std_dev: 0.2951
      std_test: 0.2926
    - frequency: 6-20
      n_dev: 1563
      n_test: 6170
      score_dev: 0.5206
      score_test: 0.5146
      std_dev: 0.2971
      std_test: 0.2903
    - frequency: 21-100
      n_dev: 1251
      n_test: 4998
      score_dev: 0.5356
      score_test: 0.5221
      std_dev: 0.2965
      std_test: 0.3002
    - frequency: '>100'
      n_dev: 530
      n_test: 2044
      score_dev: 0.566
      score_test: 0.5346
      std_dev: 0.3049
      std_test: 0.2988
    by_length:
    - length: 4
      n_dev: 345
      n_test: 1460
      score_dev: 0.5558
      score_test: 0.5088
      std_dev: 0.3166
      std_test: 0.3014
    - length: 5
      n_dev: 1626
      n_test: 6608
      score_dev: 0.5048
      score_test: 0.5094
      std_dev: 0.2933
      std_test: 0.2943
    - length: 6
      n_dev: 2492
      n_test: 9898
      score_dev: 0.5164
      score_test: 0.5129
      std_dev: 0.2934
      std_test: 0.2951
    - length: 7
      n_dev: 2102
      n_test: 8205
      score_dev: 0.5205
      score_test: 0.5115
      std_dev: 0.2931
      std_test: 0.2916
    - length: 8
      n_dev: 1497
      n_test: 6096
      score_dev: 0.5105
      score_test: 0.5176
      std_dev: 0.2972
      std_test: 0.2904
    - length: 9
      n_dev: 955
      n_test: 3514
      score_dev: 0.5207
      score_test: 0.5165
      std_dev: 0.2961
      std_test: 0.2885
    - length: 10
      n_dev: 490
      n_test: 2054
      score_dev: 0.5224
      score_test: 0.5189
      std_dev: 0.2842
      std_test: 0.2912
    - length: 11
      n_dev: 298
      n_test: 1184
      score_dev: 0.5117
      score_test: 0.5105
      std_dev: 0.2906
      std_test: 0.2932
    - length: 12
      n_dev: 132
      n_test: 602
      score_dev: 0.5379
      score_test: 0.5141
      std_dev: 0.2805
      std_test: 0.2899
    - length: 13
      n_dev: 51
      n_test: 301
      score_dev: 0.5686
      score_test: 0.554
      std_dev: 0.3205
      std_test: 0.2765
    - length: 14
      n_dev: 12
      n_test: 78
      score_dev: 0.3958
      score_test: 0.5705
      std_dev: 0.2251
      std_test: 0.3039
  semantic:
  - dataset: mturk-771
    librispeech: 16.0292
    set: dev
    synthetic: 4.3004
  - dataset: MEN
    librispeech: 18.4562
    set: test
    synthetic: 19.0248
  - dataset: WordSim-353
    librispeech: 10.9154
    set: test
    synthetic: 5.1064
  - dataset: WordSim-353-REL
    librispeech: 11.4306
    set: test
    synthetic: -1.9972
  - dataset: WordSim-353-SIM
    librispeech: 13.8719
    set: test
    synthetic: 9.3427
  - dataset: YP-130
    librispeech: 33.1014
    set: test
    synthetic: -5.5236
  - dataset: mc-30
    librispeech: 50.8251
    set: test
    synthetic: 15.4668
  - dataset: mturk-287
    librispeech: -18.0745
    set: test
    synthetic: -1.3464
  - dataset: rg-65
    librispeech: 35.0154
    set: test
    synthetic: 18.36
  - dataset: rw
    librispeech: 25.1876
    set: test
    synthetic: 10.5232
  - dataset: simLex999
    librispeech: 5.6582
    set: test
    synthetic: 3.966
  - dataset: simverb-3500
    librispeech: 8.906
    set: test
    synthetic: 0.6501
  - dataset: verb-143
    librispeech: 5.8704
    set: test
    synthetic: 25.2308
  syntactic:
  - n_dev: 200
    n_test: 2000
    score_dev: 0.5038
    score_test: 0.513
    std_dev: 0.274
    std_test: 0.5
    type: anaphor_agreement
  - n_dev: 900
    n_test: 9000
    score_dev: 0.4968
    score_test: 0.488
    std_dev: 0.3114
    std_test: 0.4999
    type: argument_structure
  - n_dev: 500
    n_test: 5000
    score_dev: 0.565
    score_test: 0.4896
    std_dev: 0.2714
    std_test: 0.4999
    type: binding
  - n_dev: 500
    n_test: 5000
    score_dev: 0.5145
    score_test: 0.5012
    std_dev: 0.2803
    std_test: 0.5
    type: control_raising
  - n_dev: 800
    n_test: 8000
    score_dev: 0.4888
    score_test: 0.5026
    std_dev: 0.2603
    std_test: 0.5
    type: determiner_noun_agreement
  - n_dev: 100
    n_test: 1000
    score_dev: 0.55
    score_test: 0.554
    std_dev: 0.2887
    std_test: 0.4973
    type: ellipsis
  - n_dev: 800
    n_test: 8000
    score_dev: 0.5719
    score_test: 0.5289
    std_dev: 0.3218
    std_test: 0.4992
    type: filler_gap_dependency
  - n_dev: 200
    n_test: 2000
    score_dev: 0.4606
    score_test: 0.5048
    std_dev: 0.271
    std_test: 0.4955
    type: irregular_forms
  - n_dev: 700
    n_test: 7000
    score_dev: 0.5425
    score_test: 0.4986
    std_dev: 0.2994
    std_test: 0.5
    type: island_effects
  - n_dev: 700
    n_test: 7000
    score_dev: 0.4839
    score_test: 0.4897
    std_dev: 0.2678
    std_test: 0.4999
    type: npi_licensing
  - n_dev: 300
    n_test: 3000
    score_dev: 0.5425
    score_test: 0.5437
    std_dev: 0.2744
    std_test: 0.4982
    type: quantifiers
  - n_dev: 600
    n_test: 6000
    score_dev: 0.515
    score_test: 0.506
    std_dev: 0.2733
    std_test: 0.5
    type: subject_verb_agreement
phonetic_clean_across:
- 0.093
- 0.0904
phonetic_clean_within:
- 0.0717
- 0.065
phonetic_other_across:
- 0.1489
- 0.1544
phonetic_other_within:
- 0.0956
- 0.0995
semantic_librispeech:
- 16.0292
- 16.76364166666667
semantic_synthetic:
- 4.3004
- 8.233633333333332
set:
- dev
- test
syntactic:
- 0.5196031746031746
- 0.5043253968253968
weighted_semantic_librispeech:
- 16.0292
- 12.209519690913936
weighted_semantic_synthetic:
- 4.3004
- 8.100163536535302
