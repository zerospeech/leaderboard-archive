author_label: Lingyun Gao et al.
index: 28
lexical_all:
- 0.5841375
- 0.581575
lexical_invocab:
- 0.62483502
- 0.6229380200000001
more:
  description:
    affiliation: Delft University of Technology
    author: Lingyun Gao, Siyuan Feng, Odette Scharenborg
    description: In this model, we use a CPC segmentation module to generate boundaries
      of audios (removed most silence segments by VAD). Then we average the features
      from pretrained CPC-big within the adjacent boundaries and use kmeans to get
      pseudo units. A bert model is used to train the language models. ABX results
      are from the baseline.
    gpu_budget: 60
    open_source: false
    parameters:
      phonetic:
        frame_shift: 0.01
        metric: cosine
      semantic:
        metric: cosine
        pooling: sum
    submitted_at: '2021-12-03T11:41:09+00:00'
    train_set: librispeech 960
    visually_grounded: false
  lexical:
    by_frequency:
    - frequency: oov
      n_dev: 5000
      n_test: 20000
      score_dev: 0.5434
      score_test: 0.5402
      std_dev: 0.3017
      std_test: 0.3035
    - frequency: 1-5
      n_dev: 1656
      n_test: 6788
      score_dev: 0.5802
      score_test: 0.5796
      std_dev: 0.2992
      std_test: 0.2999
    - frequency: 6-20
      n_dev: 1563
      n_test: 6170
      score_dev: 0.6048
      score_test: 0.6067
      std_dev: 0.2944
      std_test: 0.3015
    - frequency: 21-100
      n_dev: 1251
      n_test: 4998
      score_dev: 0.6605
      score_test: 0.6563
      std_dev: 0.2924
      std_test: 0.293
    - frequency: '>100'
      n_dev: 530
      n_test: 2044
      score_dev: 0.7392
      score_test: 0.7343
      std_dev: 0.263
      std_test: 0.2744
    by_length:
    - length: 4
      n_dev: 345
      n_test: 1460
      score_dev: 0.5906
      score_test: 0.5549
      std_dev: 0.324
      std_test: 0.3163
    - length: 5
      n_dev: 1626
      n_test: 6608
      score_dev: 0.5431
      score_test: 0.5409
      std_dev: 0.3086
      std_test: 0.3071
    - length: 6
      n_dev: 2492
      n_test: 9898
      score_dev: 0.5585
      score_test: 0.5612
      std_dev: 0.2914
      std_test: 0.3013
    - length: 7
      n_dev: 2102
      n_test: 8205
      score_dev: 0.5784
      score_test: 0.5726
      std_dev: 0.3029
      std_test: 0.3029
    - length: 8
      n_dev: 1497
      n_test: 6096
      score_dev: 0.5936
      score_test: 0.5908
      std_dev: 0.2963
      std_test: 0.3018
    - length: 9
      n_dev: 955
      n_test: 3514
      score_dev: 0.6114
      score_test: 0.6187
      std_dev: 0.3093
      std_test: 0.3003
    - length: 10
      n_dev: 490
      n_test: 2054
      score_dev: 0.676
      score_test: 0.6534
      std_dev: 0.2774
      std_test: 0.2993
    - length: 11
      n_dev: 298
      n_test: 1184
      score_dev: 0.6703
      score_test: 0.6813
      std_dev: 0.3004
      std_test: 0.2854
    - length: 12
      n_dev: 132
      n_test: 602
      score_dev: 0.7519
      score_test: 0.7166
      std_dev: 0.2538
      std_test: 0.282
    - length: 13
      n_dev: 51
      n_test: 301
      score_dev: 0.7108
      score_test: 0.7201
      std_dev: 0.271
      std_test: 0.2652
    - length: 14
      n_dev: 12
      n_test: 78
      score_dev: 0.6667
      score_test: 0.6827
      std_dev: 0.1628
      std_test: 0.2896
  semantic:
  - dataset: mturk-771
    librispeech: 7.7987
    set: dev
    synthetic: 5.3984
  - dataset: MEN
    librispeech: 4.0138
    set: test
    synthetic: 1.9796
  - dataset: WordSim-353
    librispeech: 0.3829
    set: test
    synthetic: 12.0772
  - dataset: WordSim-353-REL
    librispeech: -5.8617
    set: test
    synthetic: 2.0284
  - dataset: WordSim-353-SIM
    librispeech: 11.463
    set: test
    synthetic: 20.9569
  - dataset: YP-130
    librispeech: 18.381
    set: test
    synthetic: -11.4255
  - dataset: mc-30
    librispeech: 23.1023
    set: test
    synthetic: 16.4015
  - dataset: mturk-287
    librispeech: -10.0719
    set: test
    synthetic: -2.5634
  - dataset: rg-65
    librispeech: -0.7898
    set: test
    synthetic: 8.9779
  - dataset: rw
    librispeech: 5.55
    set: test
    synthetic: 10.8226
  - dataset: simLex999
    librispeech: 9.7257
    set: test
    synthetic: -0.9939
  - dataset: simverb-3500
    librispeech: -5.1099
    set: test
    synthetic: -3.3871
  - dataset: verb-143
    librispeech: 6.669
    set: test
    synthetic: 25.9662
  syntactic:
  - n_dev: 200
    n_test: 2000
    score_dev: 0.5463
    score_test: 0.5315
    std_dev: 0.2891
    std_test: 0.4991
    type: anaphor_agreement
  - n_dev: 900
    n_test: 9000
    score_dev: 0.5153
    score_test: 0.497
    std_dev: 0.3554
    std_test: 0.5
    type: argument_structure
  - n_dev: 500
    n_test: 5000
    score_dev: 0.5655
    score_test: 0.5775
    std_dev: 0.2992
    std_test: 0.494
    type: binding
  - n_dev: 500
    n_test: 5000
    score_dev: 0.487
    score_test: 0.5086
    std_dev: 0.3438
    std_test: 0.5
    type: control_raising
  - n_dev: 800
    n_test: 8000
    score_dev: 0.5062
    score_test: 0.4972
    std_dev: 0.2852
    std_test: 0.4998
    type: determiner_noun_agreement
  - n_dev: 100
    n_test: 1000
    score_dev: 0.5775
    score_test: 0.568
    std_dev: 0.3112
    std_test: 0.4956
    type: ellipsis
  - n_dev: 800
    n_test: 8000
    score_dev: 0.5978
    score_test: 0.5976
    std_dev: 0.3778
    std_test: 0.4904
    type: filler_gap_dependency
  - n_dev: 200
    n_test: 2000
    score_dev: 0.4688
    score_test: 0.4617
    std_dev: 0.289
    std_test: 0.497
    type: irregular_forms
  - n_dev: 700
    n_test: 7000
    score_dev: 0.5432
    score_test: 0.544
    std_dev: 0.3257
    std_test: 0.4981
    type: island_effects
  - n_dev: 700
    n_test: 7000
    score_dev: 0.5236
    score_test: 0.513
    std_dev: 0.3099
    std_test: 0.4999
    type: npi_licensing
  - n_dev: 300
    n_test: 3000
    score_dev: 0.6067
    score_test: 0.6117
    std_dev: 0.2889
    std_test: 0.4875
    type: quantifiers
  - n_dev: 600
    n_test: 6000
    score_dev: 0.515
    score_test: 0.5082
    std_dev: 0.2903
    std_test: 0.4998
    type: subject_verb_agreement
phonetic_clean_across:
- 0.083
- 0.0841
phonetic_clean_within:
- 0.0638
- 0.0671
phonetic_other_across:
- 0.149
- 0.1516
phonetic_other_within:
- 0.1022
- 0.1062
semantic_librispeech:
- 7.7987
- 4.787866666666666
semantic_synthetic:
- 5.3984
- 6.7367
set:
- dev
- test
syntactic:
- 0.5351984126984127
- 0.5317380952380952
weighted_semantic_librispeech:
- 7.7987
- 1.1275759925393019
weighted_semantic_synthetic:
- 5.3984
- 1.671793585796387
